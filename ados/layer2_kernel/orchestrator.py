"""
LangGraph Orchestrator — Multi-Agent Pipeline via StateGraph (Graph-Native)
────────────────────────────────────────────────────────────────────────────
REPLACES CSV+DuckDB with pure Neo4j graph architecture.

Architecture change:
  OLD: CSV → DuckDB → SQL → results
  NEW: CSV → Neo4j Graph → Cypher → results

Each agent is a node. Transitions are edges.
State flows through the graph accumulating results.

Flow:
  intent → discovery → query_build (Cypher) → execute (Neo4j) → trust → analyze → END
"""
from __future__ import annotations

import time
import uuid
import json
from typing import Any, Dict, List, Optional, TypedDict, Annotated

from langgraph.graph import StateGraph, END

from ados.config import get_settings
from ados.layer2_kernel.agents import (
    get_llm, run_intent_agent, run_discovery_agent,
    run_query_agent, run_trust_agent, run_analyst_agent,
    AgentResult,
)
from ados.layer3_data_fabric.lineage_service import DynamicLineageService
from ados.layer3_data_fabric.metadata_catalog import MetadataCatalog
from ados.logging_config import get_logger, set_correlation_id

logger = get_logger(__name__)


# ═══════════════════════════════════════════════════════════════════════
# STATE DEFINITION — shared state flowing through the graph
# ═══════════════════════════════════════════════════════════════════════

class PipelineState(TypedDict):
    # Input
    user_query: str
    user_role: str
    correlation_id: str
    # Context
    schema_context: str
    kg_context: str
    knowledge_graph: Any  # Neo4jKnowledgeGraph instance
    # Agent outputs
    intent: Dict[str, Any]
    discovery: Dict[str, Any]
    sql: str  # Actually Cypher, but kept for backward compat
    result_data: List[Dict[str, Any]]
    trust: Dict[str, Any]
    analysis: Dict[str, Any]
    # Pipeline tracking
    steps: List[Dict[str, Any]]
    error: Optional[str]
    status: str
    lineage_trace_id: str
    total_duration_ms: float


# ═══════════════════════════════════════════════════════════════════════
# GRAPH NODES — each node is an LLM agent
# ═══════════════════════════════════════════════════════════════════════

def node_intent(state: PipelineState) -> dict:
    """Node 1: LLM parses user intent."""
    settings = get_settings()
    llm = get_llm(settings)
    result = run_intent_agent(llm, state["user_query"], state["schema_context"])

    intent = result.data.get("intent", {})
    return {
        "intent": intent,
        "steps": state["steps"] + [{
            "step": 1, "agent": "intent_agent",
            "status": result.status,
            "duration_ms": result.execution_time_ms,
            "message": result.message,
        }],
    }


def node_discovery(state: PipelineState) -> dict:
    """Node 2: LLM discovers relevant data products."""
    settings = get_settings()
    llm = get_llm(settings)
    result = run_discovery_agent(
        llm, state["intent"], state["schema_context"], state["kg_context"]
    )

    return {
        "discovery": result.data,
        "steps": state["steps"] + [{
            "step": 2, "agent": "discovery_agent",
            "status": result.status,
            "duration_ms": result.execution_time_ms,
            "message": result.message,
        }],
    }


def node_query_build(state: PipelineState) -> dict:
    """Node 3: LLM generates Cypher query for Neo4j."""
    settings = get_settings()
    llm = get_llm(settings)
    result = run_query_agent(
        llm, state["intent"], state["discovery"], state["schema_context"]
    )

    sql = result.data.get("sql", "")
    update: dict = {
        "sql": sql,
        "steps": state["steps"] + [{
            "step": 3, "agent": "query_agent",
            "status": result.status,
            "duration_ms": result.execution_time_ms,
            "message": result.message,
        }],
    }
    # Propagate query agent errors so the pipeline state reflects them
    if result.status == "error":
        update["error"] = f"QueryAgent failed: {result.message}"
    return update


def node_execute(state: PipelineState) -> dict:
    """Node 4: Execute the Cypher query against Neo4j graph."""
    start = time.time()
    cypher = state["sql"]  # Still called "sql" for backward compat
    knowledge_graph = state.get("knowledge_graph")

    # Guard: if LLM failed to produce Cypher, skip execution
    if not cypher or not cypher.strip():
        elapsed = (time.time() - start) * 1000
        # Preserve the real error from a previous agent (e.g. rate-limit)
        prev_error = state.get("error") or "No Cypher query was generated by the LLM agent"
        logger.warning(f"node_execute: No Cypher — skipping. Reason: {prev_error}")
        return {
            "result_data": [],
            "error": prev_error,
            "status": "failed",
            "steps": state["steps"] + [{
                "step": 4, "agent": "neo4j_executor",
                "status": "error",
                "duration_ms": elapsed,
                "message": f"No Cypher to execute — {prev_error[:120]}",
            }],
        }

    try:
        # Execute the LLM-generated Cypher on Neo4j
        result = knowledge_graph.query_cypher(cypher)
        
        elapsed = (time.time() - start) * 1000
        logger.info(f"Neo4j: Cypher returned {len(result)} rows in {elapsed:.0f}ms")

        return {
            "result_data": result,
            "steps": state["steps"] + [{
                "step": 4, "agent": "neo4j_executor",
                "status": "success",
                "duration_ms": elapsed,
                "message": f"Cypher returned {len(result)} rows",
            }],
        }
    except Exception as e:
        elapsed = (time.time() - start) * 1000
        logger.error(f"Neo4j execution failed: {e}")
        return {
            "result_data": [],
            "error": str(e),
            "status": "failed",
            "steps": state["steps"] + [{
                "step": 4, "agent": "neo4j_executor",
                "status": "error",
                "duration_ms": elapsed,
                "message": str(e),
            }],
        }


def node_trust(state: PipelineState) -> dict:
    """Node 5: LLM Trust Judge validates results."""
    if state.get("error"):
        return {"trust": {"trust_score": 0, "approved": False, "assessment": state["error"]}}

    settings = get_settings()
    llm = get_llm(settings)
    result = run_trust_agent(llm, state["user_query"], state["sql"], state["result_data"])

    return {
        "trust": result.data,
        "steps": state["steps"] + [{
            "step": 5, "agent": "trust_judge",
            "status": result.status,
            "duration_ms": result.execution_time_ms,
            "message": result.message,
        }],
    }


def node_analyze(state: PipelineState) -> dict:
    """Node 6: LLM Analyst provides intelligent insights."""
    if state.get("error") or not state.get("result_data"):
        return {"analysis": {"summary": "No data to analyze."}, "status": "failed"}

    settings = get_settings()
    llm = get_llm(settings)
    result = run_analyst_agent(llm, state["user_query"], state["sql"], state["result_data"])

    return {
        "analysis": result.data,
        "status": "completed",
        "steps": state["steps"] + [{
            "step": 6, "agent": "analyst_agent",
            "status": result.status,
            "duration_ms": result.execution_time_ms,
            "message": result.message,
        }],
    }


# ═══════════════════════════════════════════════════════════════════════
# CONDITIONAL EDGES
# ═══════════════════════════════════════════════════════════════════════

def should_continue_after_execute(state: PipelineState) -> str:
    """After execution, go to trust or END if failed."""
    if state.get("error"):
        return END
    return "trust"


# ═══════════════════════════════════════════════════════════════════════
# GRAPH BUILDER
# ═══════════════════════════════════════════════════════════════════════

def build_pipeline_graph() -> StateGraph:
    """Build the LangGraph pipeline."""
    graph = StateGraph(PipelineState)

    # Add nodes
    graph.add_node("intent", node_intent)
    graph.add_node("discovery", node_discovery)
    graph.add_node("query_build", node_query_build)
    graph.add_node("execute", node_execute)
    graph.add_node("trust", node_trust)
    graph.add_node("analyze", node_analyze)

    # Add edges (linear flow with conditional after execute)
    graph.set_entry_point("intent")
    graph.add_edge("intent", "discovery")
    graph.add_edge("discovery", "query_build")
    graph.add_edge("query_build", "execute")
    graph.add_conditional_edges("execute", should_continue_after_execute, {
        "trust": "trust",
        END: END,
    })
    graph.add_edge("trust", "analyze")
    graph.add_edge("analyze", END)

    return graph


# ═══════════════════════════════════════════════════════════════════════
# ORCHESTRATOR — wraps the LangGraph pipeline
# ═══════════════════════════════════════════════════════════════════════

class LangGraphOrchestrator:
    """
    Orchestrates the full ADOS pipeline via LangGraph.
    Each step is an LLM agent. No hardcoded logic.
    """

    def __init__(
        self,
        catalog: MetadataCatalog,
        knowledge_graph,  # Neo4jKnowledgeGraph
        lineage: DynamicLineageService,
    ):
        self._catalog = catalog
        self._kg = knowledge_graph
        self._lineage = lineage
        self._graph = build_pipeline_graph()
        self._compiled = self._graph.compile()
        logger.info("LangGraph orchestrator compiled and ready (graph-native)")

    def process_query(self, user_query: str, user_role: str = "analyst") -> Dict[str, Any]:
        """
        Run the full LangGraph pipeline for a user query.
        Returns the final state with all agent results.
        """
        cid = set_correlation_id()
        start = time.time()

        logger.info(f"╔═ Pipeline Start: '{user_query}' ═══")

        # Build initial state
        initial_state: PipelineState = {
            "user_query": user_query,
            "user_role": user_role,
            "correlation_id": cid,
            "schema_context": self._catalog.get_schema_context(),
            "kg_context": self._kg.get_context_for_llm() if self._kg else "",
            "knowledge_graph": self._kg,  # Pass the graph instance for execution
            "intent": {},
            "discovery": {},
            "sql": "",  # Will contain Cypher
            "result_data": [],
            "trust": {},
            "analysis": {},
            "steps": [],
            "error": None,
            "status": "running",
            "lineage_trace_id": "",
            "total_duration_ms": 0,
        }

        # Run the graph
        final_state = self._compiled.invoke(initial_state)

        # Record lineage
        lineage_id = self._record_lineage(final_state)
        final_state["lineage_trace_id"] = lineage_id
        final_state["total_duration_ms"] = round((time.time() - start) * 1000, 2)

        if not final_state.get("status") or final_state["status"] == "running":
            final_state["status"] = "completed"

        logger.info(
            f"╚═ Pipeline Complete: {final_state['status']}, "
            f"trust={final_state.get('trust', {}).get('trust_score', 'N/A')}, "
            f"rows={len(final_state.get('result_data', []))} "
            f"in {final_state['total_duration_ms']:.0f}ms ═══"
        )

        return final_state

    def _record_lineage(self, state: Dict[str, Any]) -> str:
        """Record the lineage trace from the pipeline execution."""
        graph = self._lineage.create_trace()

        # Source nodes — from discovery, fallback to catalog registered products
        products = state.get("discovery", {}).get("relevant_products", [])
        if not products:
            # Fallback: use all products registered in the catalog
            products = list(self._catalog.list_products())
        if not products:
            # Last resort: use a generic name
            products = ["data_source"]

        source_ids = []
        for p in products:
            sid = self._lineage.add_node(graph, "source", p, {"type": "csv"})
            source_ids.append(sid)

        # Transform node: LLM-Generated Cypher
        txf_id = self._lineage.add_node(graph, "transform", "LLM-Generated Cypher",
                                        {"cypher": state.get("sql", "")[:200]})
        for sid in source_ids:
            self._lineage.add_edge(graph, sid, txf_id, "read")

        # Analysis node
        analysis_id = self._lineage.add_node(graph, "transform", "LLM Analysis",
                                             {"agent": "analyst_agent"})
        self._lineage.add_edge(graph, txf_id, analysis_id, "analyze")

        # Sink node
        sink_id = self._lineage.add_node(graph, "sink", "Certified Result",
                                         {"rows": len(state.get("result_data", []))})
        self._lineage.add_edge(graph, analysis_id, sink_id, "certify")

        self._lineage.commit(graph)
        return graph.trace_id
